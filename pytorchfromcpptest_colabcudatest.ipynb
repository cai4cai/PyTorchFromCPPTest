{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMQqby1Jlh8NEuWGMZu6zLF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cai4cai/PyTorchFromCPPTest/blob/main/pytorchfromcpptest_colabcudatest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.version)\n",
        "!/usr/local/bin/python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxim3InnARsR",
        "outputId": "8151f2f9-acbd-4064-962e-65ef9577196a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.6 (main, May 29 2023, 11:10:38) [GCC 11.3.0]\n",
            "Python 3.10.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crav7xMDyHYh",
        "outputId": "21e51301-1617-4c41-d526-9ec059809476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "--2023-07-29 15:42:15--  https://github.com/cai4cai/PyTorchFromCPPTest/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/cai4cai/PyTorchFromCPPTest/zip/refs/heads/main [following]\n",
            "--2023-07-29 15:42:16--  https://codeload.github.com/cai4cai/PyTorchFromCPPTest/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.121.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.121.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘main.zip’\n",
            "\n",
            "main.zip                [ <=>                ]  17.44K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2023-07-29 15:42:16 (2.47 MB/s) - ‘main.zip’ saved [17860]\n",
            "\n",
            "Archive:  main.zip\n",
            "e15b6fb2b6e8da212dc57b072356511af2b30370\n",
            "   creating: PyTorchFromCPPTest-main/\n",
            "   creating: PyTorchFromCPPTest-main/.github/\n",
            "   creating: PyTorchFromCPPTest-main/.github/workflows/\n",
            "  inflating: PyTorchFromCPPTest-main/.github/workflows/cmake.yml  \n",
            "  inflating: PyTorchFromCPPTest-main/.github/workflows/cpplint.yml  \n",
            "  inflating: PyTorchFromCPPTest-main/.github/workflows/flake8.yml  \n",
            "  inflating: PyTorchFromCPPTest-main/.gitignore  \n",
            "  inflating: PyTorchFromCPPTest-main/CMakeLists.txt  \n",
            "  inflating: PyTorchFromCPPTest-main/CPPLINT.cfg  \n",
            "  inflating: PyTorchFromCPPTest-main/LICENSE  \n",
            "  inflating: PyTorchFromCPPTest-main/README.md  \n",
            "  inflating: PyTorchFromCPPTest-main/pycustomtorchmodule.py  \n",
            "  inflating: PyTorchFromCPPTest-main/pytorchfromcpptest.cpp  \n",
            "  inflating: PyTorchFromCPPTest-main/pytorchfromcpptest_colabcudatest.ipynb  \n",
            "  inflating: PyTorchFromCPPTest-main/pytorchfromcpptestwiththreadedloop.cpp  \n",
            "-- The C compiler identification is GNU 11.3.0\n",
            "-- The CXX compiler identification is GNU 11.3.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- clang-tidy not found. Skipping corresponding checks.\n",
            "-- Found Python: /usr/local/bin/python (found version \"3.10.6\") found components: Interpreter Development Development.Module Development.Embed \n",
            "-- Found python: /usr/local/bin/python\n",
            "-- Found torch.utils.cmake_prefix_path: /usr/local/lib/python3.10/dist-packages/torch/share/cmake\n",
            "-- Found CUDA: /usr/local/cuda (found version \"11.8\") \n",
            "-- The CUDA compiler identification is NVIDIA 11.8.89\n",
            "-- Detecting CUDA compiler ABI info\n",
            "-- Detecting CUDA compiler ABI info - done\n",
            "-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped\n",
            "-- Detecting CUDA compile features\n",
            "-- Detecting CUDA compile features - done\n",
            "-- Caffe2: CUDA detected: 11.8\n",
            "-- Caffe2: CUDA nvcc is: /usr/local/cuda/bin/nvcc\n",
            "-- Caffe2: CUDA toolkit directory: /usr/local/cuda\n",
            "-- Caffe2: Header version is: 11.8\n",
            "-- /usr/local/cuda/lib64/libnvrtc.so shorthash is 672ee683\n",
            "-- USE_CUDNN is set to 0. Compiling without cuDNN support\n",
            "-- Autodetected CUDA architecture(s):  7.5\n",
            "-- Added CUDA NVCC flags for: -gencode;arch=compute_75,code=sm_75\n",
            "\u001b[33mCMake Warning at /usr/local/lib/python3.10/dist-packages/torch/share/cmake/Torch/TorchConfig.cmake:22 (message):\n",
            "  static library kineto_LIBRARY-NOTFOUND not found.\n",
            "Call Stack (most recent call first):\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/share/cmake/Torch/TorchConfig.cmake:127 (append_torchlib_if_found)\n",
            "  CMakeLists.txt:42 (find_package)\n",
            "\n",
            "\u001b[0m\n",
            "-- Found Torch: /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch.so  \n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "-- Found Threads: TRUE  \n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/build\n",
            "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/pytorchfromcpptest.dir/pytorchfromcpptest.cpp.o\u001b[0m\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX executable pytorchfromcpptest\u001b[0m\n",
            "[ 50%] Built target pytorchfromcpptest\n",
            "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/pytorchfromcpptestwiththreadedloop.dir/pytorchfromcpptestwiththreadedloop.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable pytorchfromcpptestwiththreadedloop\u001b[0m\n",
            "[100%] Built target pytorchfromcpptestwiththreadedloop\n"
          ]
        }
      ],
      "source": [
        "!pip3 install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!rm -f main.zip*\n",
        "!wget https://github.com/cai4cai/PyTorchFromCPPTest/archive/refs/heads/main.zip\n",
        "!unzip -o main.zip\n",
        "# There is an old version of pathlib living in /usr/local/lib/python3.10/dist-packages/\n",
        "# Let the one in /usr/lib/python3.10/dist-packages/ be used\n",
        "!rm /usr/local/lib/python3.10/dist-packages/pathlib.py\n",
        "!mkdir -p build\n",
        "!cd build; cmake ../PyTorchFromCPPTest-main\n",
        "!cd build; make"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./build/pytorchfromcpptest"
      ],
      "metadata": {
        "id": "E99AvOqXT93a",
        "outputId": "24fb1fe5-b62c-40f4-fc95-b7cc09b13a82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting test from c++\n",
            "PyTorch version: 2.0.1\n",
            "CUDA is available. Running on GPU.\n",
            "Random 2x3 tensor (c++ side):\n",
            " 0.1436  0.1151  0.7989\n",
            " 0.4608  0.8150  0.1522\n",
            "[ CUDAFloatType{2,3} ]\n",
            "Custom python module loaded from /content/PyTorchFromCPPTest-main\n",
            "Start python op\n",
            "tensor([[0.1436, 0.1151, 0.7989],\n",
            "        [0.4608, 0.8150, 0.1522]], device='cuda:0')\n",
            "Python return value \n",
            " 0.2872  0.2303  1.5978\n",
            " 0.9215  1.6300  0.3043\n",
            "[ CUDAFloatType{2,3} ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./build/pytorchfromcpptestwiththreadedloop"
      ],
      "metadata": {
        "id": "uLbpCle6UCPM",
        "outputId": "7e8be38d-aa9c-4f69-e0b6-f62d53bee5f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting test from c++\n",
            "PyTorch version: 2.0.1\n",
            "CUDA is available. Running on GPU.\n",
            "Example globaltensor (c++ side):\n",
            " 0\n",
            " 1\n",
            " 2\n",
            "[ CUDALongType{3} ]\n",
            "Custom python module loaded from /content/PyTorchFromCPPTest-main\n",
            "Launching thread at iter 0 with cloned tensor \n",
            " 0\n",
            " 1\n",
            " 2\n",
            "[ CUDALongType{3} ]\n",
            "Start python op\n",
            "tensor([0, 1, 2], device='cuda:0')\n",
            "tensor([0, 1, 2], device='cuda:0')\n",
            "Thread is busy at iter 1\n",
            "Thread is busy at iter 2\n",
            "Thread is busy at iter 3\n",
            "Thread is busy at iter 4\n",
            "Thread is busy at iter 5\n",
            "Thread is busy at iter 6\n",
            "Thread is busy at iter 7\n",
            "Thread is busy at iter 8\n",
            "Thread is busy at iter 9\n",
            "Thread is busy at iter 10\n",
            "Python return value (in c++) \n",
            " 0\n",
            " 2\n",
            " 4\n",
            "[ CUDALongType{3} ]\n",
            "Launching thread at iter 11 with cloned tensor \n",
            " 11\n",
            " 12\n",
            " 13\n",
            "[ CUDALongType{3} ]\n",
            "Start python op\n",
            "tensor([0, 1, 2], device='cuda:0')\n",
            "tensor([11, 12, 13], device='cuda:0')\n",
            "Thread is busy at iter 12\n",
            "Thread is busy at iter 13\n",
            "Thread is busy at iter 14\n",
            "Thread is busy at iter 15\n",
            "Thread is busy at iter 16\n",
            "Thread is busy at iter 17\n",
            "Thread is busy at iter 18\n",
            "Thread is busy at iter 19\n",
            "Thread is busy at iter 20\n",
            "Python return value (in c++) \n",
            " 11\n",
            " 13\n",
            " 15\n",
            "[ CUDALongType{3} ]\n",
            "Launching thread at iter 21 with cloned tensor \n",
            " 21\n",
            " 22\n",
            " 23\n",
            "[ CUDALongType{3} ]\n",
            "Start python op\n",
            "tensor([0, 1, 2], device='cuda:0')\n",
            "tensor([21, 22, 23], device='cuda:0')\n",
            "Thread is busy at iter 22\n",
            "Thread is busy at iter 23\n",
            "Thread is busy at iter 24\n",
            "Thread is busy at iter 25\n",
            "Thread is busy at iter 26\n",
            "Thread is busy at iter 27\n",
            "Thread is busy at iter 28\n",
            "Thread is busy at iter 29\n",
            "Thread is busy at iter 30\n",
            "Python return value (in c++) \n",
            " 21\n",
            " 23\n",
            " 25\n",
            "[ CUDALongType{3} ]\n",
            "Launching thread at iter 31 with cloned tensor \n",
            " 31\n",
            " 32\n",
            " 33\n",
            "[ CUDALongType{3} ]\n",
            "Start python op\n",
            "tensor([0, 1, 2], device='cuda:0')\n",
            "tensor([31, 32, 33], device='cuda:0')\n",
            "Thread is busy at iter 32\n",
            "Thread is busy at iter 33\n",
            "Thread is busy at iter 34\n",
            "Thread is busy at iter 35\n",
            "Thread is busy at iter 36\n",
            "Thread is busy at iter 37\n",
            "Thread is busy at iter 38\n",
            "Thread is busy at iter 39\n",
            "Thread is busy at iter 40\n",
            "Python return value (in c++) \n",
            " 31\n",
            " 33\n",
            " 35\n",
            "[ CUDALongType{3} ]\n",
            "Launching thread at iter 41 with cloned tensor \n",
            " 41\n",
            " 42\n",
            " 43\n",
            "[ CUDALongType{3} ]\n",
            "Start python op\n",
            "tensor([0, 1, 2], device='cuda:0')\n",
            "tensor([41, 42, 43], device='cuda:0')\n",
            "Thread is busy at iter 42\n",
            "Thread is busy at iter 43\n",
            "Thread is busy at iter 44\n",
            "Thread is busy at iter 45\n",
            "Thread is busy at iter 46\n",
            "Thread is busy at iter 47\n",
            "Thread is busy at iter 48\n",
            "Thread is busy at iter 49\n",
            "Thread is busy at iter 50\n",
            "Python return value (in c++) \n",
            " 41\n",
            " 43\n",
            " 45\n",
            "[ CUDALongType{3} ]\n",
            "Launching thread at iter 51 with cloned tensor \n",
            " 51\n",
            " 52\n",
            " 53\n",
            "[ CUDALongType{3} ]\n",
            "Start python op\n",
            "tensor([0, 1, 2], device='cuda:0')\n",
            "tensor([51, 52, 53], device='cuda:0')\n",
            "Thread is busy at iter 52\n",
            "Thread is busy at iter 53\n",
            "Thread is busy at iter 54\n",
            "Thread is busy at iter 55\n",
            "Thread is busy at iter 56\n",
            "Thread is busy at iter 57\n",
            "Thread is busy at iter 58\n",
            "Thread is busy at iter 59\n",
            "Thread is busy at iter 60\n",
            "Python return value (in c++) \n",
            " 51\n",
            " 53\n",
            " 55\n",
            "[ CUDALongType{3} ]\n",
            "Launching thread at iter 61 with cloned tensor \n",
            " 61\n",
            " 62\n",
            " 63\n",
            "[ CUDALongType{3} ]\n",
            "Start python op\n",
            "tensor([0, 1, 2], device='cuda:0')\n",
            "tensor([61, 62, 63], device='cuda:0')\n",
            "Thread is busy at iter 62\n",
            "Thread is busy at iter 63\n",
            "Thread is busy at iter 64\n",
            "Thread is busy at iter 65\n",
            "Thread is busy at iter 66\n",
            "Thread is busy at iter 67\n",
            "Thread is busy at iter 68\n",
            "Thread is busy at iter 69\n",
            "Thread is busy at iter 70\n",
            "Python return value (in c++) \n",
            " 61\n",
            " 63\n",
            " 65\n",
            "[ CUDALongType{3} ]\n",
            "Launching thread at iter 71 with cloned tensor \n",
            " 71\n",
            " 72\n",
            " 73\n",
            "[ CUDALongType{3} ]\n",
            "Start python op\n",
            "tensor([0, 1, 2], device='cuda:0')\n",
            "tensor([71, 72, 73], device='cuda:0')\n",
            "Thread is busy at iter 72\n",
            "Thread is busy at iter 73\n",
            "Thread is busy at iter 74\n",
            "Thread is busy at iter 75\n",
            "Thread is busy at iter 76\n",
            "Thread is busy at iter 77\n",
            "Thread is busy at iter 78\n",
            "Thread is busy at iter 79\n",
            "Thread is busy at iter 80\n",
            "Python return value (in c++) \n",
            " 71\n",
            " 73\n",
            " 75\n",
            "[ CUDALongType{3} ]\n",
            "Launching thread at iter 81 with cloned tensor \n",
            " 81\n",
            " 82\n",
            " 83\n",
            "[ CUDALongType{3} ]\n",
            "Start python op\n",
            "tensor([0, 1, 2], device='cuda:0')\n",
            "tensor([81, 82, 83], device='cuda:0')\n",
            "Thread is busy at iter 82\n",
            "Thread is busy at iter 83\n",
            "Thread is busy at iter 84\n",
            "Thread is busy at iter 85\n",
            "Thread is busy at iter 86\n",
            "Thread is busy at iter 87\n",
            "Thread is busy at iter 88\n",
            "Thread is busy at iter 89\n",
            "Thread is busy at iter 90\n",
            "Python return value (in c++) \n",
            " 81\n",
            " 83\n",
            " 85\n",
            "[ CUDALongType{3} ]\n",
            "Launching thread at iter 91 with cloned tensor \n",
            " 91\n",
            " 92\n",
            " 93\n",
            "[ CUDALongType{3} ]\n",
            "Start python op\n",
            "tensor([0, 1, 2], device='cuda:0')\n",
            "tensor([91, 92, 93], device='cuda:0')\n",
            "Thread is busy at iter 92\n",
            "Thread is busy at iter 93\n",
            "Thread is busy at iter 94\n",
            "Thread is busy at iter 95\n",
            "Thread is busy at iter 96\n",
            "Thread is busy at iter 97\n",
            "Thread is busy at iter 98\n",
            "Thread is busy at iter 99\n",
            "Python return value (in c++) \n",
            " 91\n",
            " 93\n",
            " 95\n",
            "[ CUDALongType{3} ]\n"
          ]
        }
      ]
    }
  ]
}